 ,6"Yb.        ,p6"bo  pd*"*b. `7Mb,od8 M****** 
8)   MM       6M'  OO (O)   j8   MM' "'.M       
 ,pm9MM mmmmm 8M          ,;j9   MM    |bMMAg.  
8M   MM       YM.    , ,-='      MM         `Mb 
`Moo9^Yo.      YMbmd' Ammmmmmm .JMML.        jM 
                                       (O)  ,M9 
                                        6mmm9

Singularity Systems: Zero to Hero
--------------------------------------------------------------------------------
Contents:
  0. au197
  1. dfdx(nd)
  2. brrr
  3. pt2
  4. cloud
Appendix:
  A. c2r5 <-- HERE
    Part 0: evaluation speedrun — interpreter
    Part 1: compilation frontend — parser
    Part 2: compilation middlend — optimizer
    Part 3: compilation backend — generator
  B. trs
  C. licurs
--------------------------------------------------------------------------------

In chapter 3 part 0, we talked about history rhyming.

----------
This
observation is conveyed well in Julia's manifesto[0] which riffs on Greenspun's
Tenth Rule of Programming.

  > Any sufficiently complicated machine learning system contains an ad-hoc,
    informally-specified, bug-ridden, slow implementation of half of a
    programming language


  > Can we build systems that treat numerics, derivatives and parallelism as
    first-class features, without sacrificing traditional programming ideas and
    wisdom? This is the foundational question which languages over the coming
    decade will have to answer.

newgen python zoomers need traditional wisdom
->
While the the productivity of the Python language and it's scientific computing
ecosystem foster a welcoming hackability to machine learning infrastructure,
the frameworks being built today to support changing models and hardware are
looking a lot more like traditional programming languages and compilers.

for classic wisdom, go to appendix a to review programming languages and
compiler construction.
------


traditional wisdom of programming languages
and compiler construction. In PT2, we built ... . also, if you are interested
in working one level lower than pytorch2 such as kernel languages for parallel
machines such as Triton (covered in the next appendix).

Programming languages are specifications, while interpretation and compilation
are implementations.

---------------------------
Part 0: evaluation speedrun
---------------------------
  0a — arithmetic
  0b — bindings, functions
  0c — control flow
  0d — heap



Programming languages have a dual nature to them. On one hand, logicians treat
them as mathematical objects whose semantics (a function from programs to values)
are amenable to formalization. e.g. SML, Scheme, WASM. On the other, engineers
treat them as tools for their trade whose purpose is to build applications.
eg: Python, Javascript, and Ruby.

Starting the study of the principles of programming languages with definitional
interpreters is convenient as it allows us to operationalize a common core of
semantics without worrying about the semantic chasm that lies between syntax and
the electrons. Rather than use the chip's implementation with microcode as the
interprter, we will build our own interpreter in software. In the development of
our C0 interpreter, we won't smoke test it with too many programs, since 1. the
focus here is on principles of programming languages and 2. there is close to no
real usage of C0 outside CMU. In the next document, we will add the complexity
of the semantic chasm back in by implementing a compiler for C89, targeting RV32I.

The data an interpreter (and compiler) uses to represent a program is abstract
syntax, in contrast to the concrete syntax — this distinction was introduced in
Landin's infamous paper: Next 700 Programming Languages. Parsing maps this
concrete syntax to abstract syntax, and evaluating maps the abstract syntax to a
value. If you take a step back, a parser and evaluator are adjoint functors to
one another, just like probability and statistics. A parser is a function that
maps information to data (abstract syntax), and an evaluator is a function that
maps data back to information. Coloquially, a parser lifts the representation
and the evaluator lowers it. Most of the time, the abstract syntax is
represented with a tree.

0a — arithmetic
---------------


References
----------
[0]: https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
[1]: https://sci-hub.se/https://doi.org/10.1038/nature14539
[2]: https://dl.acm.org/doi/10.1145/3620665.3640366
[3]: https://wiki.c2.com/?MooresLaw
[4]: https://arxiv.org/abs/2001.08361
[5]: https://www.youtube.com/watch?v=3LVeEjsn8Ts
[6]: https://www.youtube.com/watch?v=4HgShra-KnY

[0]: https://math.mit.edu/~edelman/publications/on_machine_learning.pdf
[1]: https://wiki.c2.com/?PhilipGreenspun
[2]: https://papl.cs.brown.edu/
[3]: https://cs.brown.edu/courses/cs173/2012/book/
[4]: https://www.plai.org/
[5]: https://mitpress.mit.edu/9780262047760/essentials-of-compilation/
[6]: https://github.com/rambhawan/Computer-Compiler-Lang/blob/master/Advanced%20Compiler%20Design%20and%20Implementation.pdf
[7]: https://cs.au.dk/~amoeller/spa/
[8]: https://link.springer.com/book/10.1007/978-3-030-80515-9
