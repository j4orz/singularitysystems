           ,,                                     ,,                      ,,                   
 .M"""bgd  db                                   `7MM                      db   mm              
,MI    "Y                                         MM                           MM              
`MMb.    `7MM  `7MMpMMMb.  .P"Ybmmm `7MM  `7MM    MM   ,6"Yb.  `7Mb,od8 `7MM mmMMmm `7M'   `MF'
  `YMMNq.  MM    MM    MM :MI  I8     MM    MM    MM  8)   MM    MM' "'   MM   MM     VA   ,V  
.     `MM  MM    MM    MM  WmmmP"     MM    MM    MM   ,pm9MM    MM       MM   MM      VA ,V   
Mb     dM  MM    MM    MM 8M          MM    MM    MM  8M   MM    MM       MM   MM       VVV    
P"Ybmmd" .JMML..JMML  JMML.YMMMMMb    `Mbod"YML..JMML.`Moo9^Yo..JMML.   .JMML. `Mbmo    ,V     
                          6'     dP                                                    ,V      
                          Ybmmmd'                                                   OOb"       
                                                                                               
                                                                                               
 .M"""bgd                   mm                                                                 
,MI    "Y                   MM                                                                 
`MMb.  `7M'   `MF',pP"Ybd mmMMmm .gP"Ya `7MMpMMMb.pMMMb.  ,pP"Ybd                              
  `YMMNq.VA   ,V  8I   `"   MM  ,M'   Yb  MM    MM    MM  8I   `"                              
.     `MM VA ,V   `YMMMa.   MM  8M""""""  MM    MM    MM  `YMMMa.                              
Mb     dM  VVV    L.   I8   MM  YM.    ,  MM    MM    MM  L.   I8                              
P"Ybmmd"   ,V     M9mmmP'   `Mbmo`Mbmmd'.JMML  JMML  JMML.M9mmmP'                              
          ,V                                                                                   
       OOb"

Singularity Systems: Zero to Hero

Researchers in artificial intelligence talk about research debt[0] with respect
to model development. The same applies to the infrastructure that underlies these
deep neural networks. Building deep learning compilers (and chips) have been,
and *is* currently an open research problem: todays leading deep learning
framework was released[1] less than a decade ago during my senior year of
highschool, not to mention the 2.0 release[2] with torch.compile functionality
being released in 2023.

To provide some more perspective, at the time of writing, there are 37 symposiums
in the list of NeurIPS proceedings[3], 36 symposiums in the list of Hot Chips
proceedings[4], but only *6 symposiums* in the list of MLSys proceedings[5]! Many
toy autograds exist which are the software 2.0 equivalent of calculator
interpreters capable of evaluating arithmetic. These are excellent in providing
intuition for backpropagation (calculus on a computational graph), a very
important abstraction to understand considering how leaky it is (think gradient
initialization and normalization). However, there are absolutely zero resources
that dive deeper into cutting your teeth on the advanced capabilities of PyTorch
such as torch.compile and D(istributed)Tensor. If linux has xv6[6], clang has
chibicc[7], and llvm has qbe[8], then pytorch is missing its equivalent. The
next best thing is to peek behind the curtains at the actual PyTorch source which
is close to impossible with its hundreds of thousands of lines of code.

Singularity Systems bridges this gap in the ecosystem for engineers interested
in systems programming and performance engineering of deep learning. Over the
course of 10 hours worth of lectures, you will build a deep learning interpreter
and compiler that maps torch.tensor to WGSL/CUDA line by line, from scratch.
There's also a brief appendix on how traditional compiler techniques and
infrastructure transfer over to tensor compilers by building a compiler that maps
C89 to RV32I. By the end of Singularity Systems, you will be better equipped to
contribute to opensource projects like pytorch(~100kLOC) and tinygrad(~10kLOC).
A good next step is to head on over to the latter's bounties[9].

Prereqs:
- solid deep learning (gpt2 && llama2 && r1)
- solid systems programming (C || C++ || Rust)

Syllabus:
  1. dfdx
  2. lego
  3. brrr
  4. pt2
  A. ctoriscv

[0]: https://distill.pub/2017/research-debt/
[1]: https://soumith.ch/blog/2023-12-17-pytorch-design-origins.md.html
[2]: https://pytorch.org/assets/pytorch2-2.pdf
[3]: https://papers.nips.cc/
[4]: https://hotchips.org/archives/
[5]: https://proceedings.mlsys.org/
[6]: https://github.com/mit-pdos/xv6-public
[7]: https://github.com/rui314/chibicc
[8]: https://c9x.me/compile/
[9]: https://docs.google.com/spreadsheets/d/1WKHbT-7KOgjEawq5h5Ic1qUWzpfAzuD_J06N1JwOCGs